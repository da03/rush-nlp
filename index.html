---
layout: page
title: Main
weight: 1.5
show: 1
---

<div class="col-7">
    <center>
  <table>
<tr><td style="padding:10px 90px 10px 0px">
      <img width="200px" class="img-rounded" src="https://avatars.githubusercontent.com/u/5753959?v=4" />
  </td><td style="padding:10px">
    <center>
    <h1>Yuntian Deng</h1>
    <b>Young Investigator (Postdoc)</b>, AI2<br>
    <b>Incoming Assistant Professor</b>, Waterloo CS (Starts Fall '24)<br>
    <b>Faculty Affiliate</b>, Vector Institute (Starts Fall '24)<br>
    PhD in CS, Harvard<br>
    <span style="font-size:16px"><a href="cv/cv.comp.pdf">[CV]</a> <a href="https://scholar.google.com/citations?user=tk0e5lYAAAAJ&hl=en&oi=ao">[Google Scholar]</a> <a href="https://twitter.com/yuntiandeng">[Twitter]</a></span> </h1> <br>
</center>

      </td>
  </tr>
  </table>
  </center>
<br>
</div>

<p style="font-size: 16px">

My research interests center on the intersection of natural language processing, machine learning, and multi-agent systems. Specifically, I am interested in exploring how large language models (LLMs) can communicate and collaborate to solve complex tasks together, and how they can be trained to specialize in different domains for a division of labor. My key focus areas include:

<ul style="font-size: 16px">
    <li><strong>Inducing Latent Language for Inter-LLM Communication:</strong> Developing methods to induce a specialized language for LLM communication, thereby enabling LLMs to leverage each otherâ€™ s expertise.</li>
    <li><strong>Communication for Models Across Modalities:</strong> Extending Inter-LLM communication methods to enable collaboration among models that specialize in different modalities, such as language, image, and sensory data.</li>
    <li><strong>Collaborative Training for Division of Labor among Models:</strong> Exploring ways to foster a division of labor among models, using communication as a tool to distribute knowledge among them during the training process.</li>
</ul>

</p>

<p style="font-size: 16px">
I also work on <a href="projects/">open-source</a> projects such as <a href="https://aclanthology.org/P17-4012/">OpenNMT</a>, <a href="https://im2markup.yuntiandeng.com/">Im2LaTeX</a>, <a href="https://huggingface.co/spaces/yuntian-deng/latex2im">LaTeX2Im</a>, and <a href="https://steganography.live">Steganography</a> to make my research efforts more readily available for developers and researchers.
</p>

<!--h4> Statements </h4>
<span style="font-size: 16px"><a href="cv/research_statement.pdf">[Research Statement]</a> <a href="cv/teaching_statement_and_evaluations.pdf">[Teaching Statement]</a> <a href="cv/interdisciplinary_statement.pdf">[Interdisciplinary Statement]</a> <a href="cv/diversity_statement.pdf">[Diversity Statement]</a></span-->


<h4> News </h4>
<ul style="font-size: 16px">
    <li>Mar 29, 2023: <a href="https://openaiwatch.com/">OpenAIWatch.com</a> is launched! It tracks GPT-4's nondeterministic behavior even with greedy decoding in unicorn illustrations. ðŸ¦„ 
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1641108596510343168" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Mar 29, 2023: Our <a href="https://huggingface.co/spaces/yuntian-deng/ChatGPT">GPT Chatbot</a>, based on Yuvraj Sharma's <a href="https://huggingface.co/spaces/ysharma/ChatGPT4">code</a>, is now live! It provides free acess to GPT with the aim of collecting dialogue data for research purposes.
    </li>
    <li>Oct 18, 2022: Our latest paper, <a href="https://aclanthology.org/2022.emnlp-main.815.pdf">Model Criticism for Long-Form Text Generation</a>, is now publicly available! This paper uses model criticism in latent space to quantify various notions of high-level coherence in long-form text generation.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1582410985226108930" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Oct 12, 2022: <a href="https://huggingface.co/spaces/yuntian-deng/latex2im">Markup-to-Image Diffusion Models demo</a> is now live! This project uses a diffusion model to learn how to render various types of markups, including LaTeX.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1580255172340879360" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Jun 2, 2020: Our latest paper, <a href="https://papers.nips.cc/paper/2020/file/01a0683665f38d8e5e567b3b15ca98bf-Paper.pdf">Cascaded Text Generation with Markov Transformers</a>, is available! It allows parallel, fast, autoregressive, and accurate text generation using a high-order Markov model.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1267866675904417801" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Apr 26, 2020: Introducing <a href="https://openreview.net/pdf?id=B1l4SgHKDH">Residual Energy-Based Models for Text Generation</a>, a globally-normalized approach to text generation! Our approach uses a global discriminator to guide the traditional locally-normalized language model to produce text that's more indistinguishable from human-written text.
    </li>
    <li>Sep 5, 2019: <a href="https://steganography.live">Neural Linguistic Steganography demo</a> is now live! This project lets you hide secret messages in natural language using arithmetic coding.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1169647490284605443" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Dec 19, 2016: Excited to introduce <a href="http://opennmt.net">OpenNMT</a>, an open-source neural machine translation toolkit developed for industrial and academic use.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/810900018907533313" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Sep 19, 2016: Excited to announce that we've provided a solution to OpenAI's <a href="https://github.com/openai/requests-for-research/blob/master/_requests_for_research/im2latex.html">requests-for-research im2latex challenge</a> using neural sequence-to-sequence learning! Check out the visualizations <a href="https://im2markup.yuntiandeng.com">here</a>.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/777901557585178624" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
</ul>

<!--h3> Current Research Area </h3>
<p style="font-size: 18px">
<ul style="font-size: 18px">
  <li> Deep generative models for probabilistic text generation. </li>
</ul>
</p-->

<h4>Selected Papers</h4>

<table>
{% for paper in site.data.papers.notable %}

  <tr><td style="padding:10px">
      {% if paper.image %}
      <a href="{{paper.pdf}}"><img width="300px" style="min-width:100px" src="{{paper.image}}"></a>
      {% else %}
      <a href="{{paper.pdf}}"><img height="75px" style="min-width:100px" src="https://avatar.tobi.sh/{{paper.title}}"></a>

      {% endif %}
</td><td style="padding:10px; font-size: 16px">
<a class="paper" href="{{paper.pdf}}">
{{paper.title}}
</a><br>
{{paper.authors}}.<br>
{{paper.conference}} <br>

<br>

</td></tr>

{% endfor %}
</table>


<!--h4>Contact</h4>

<div class="paper-section">
    Science and Engineering Complex 5.443 <br>
    150 Western Avenue <br>
    Boston, MA 02134 <br>
    USA
</div-->
<br>
