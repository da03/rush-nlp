---
layout: page
title: Main
weight: 1.5
show: 1
---

<div class="col-7 text-center">
  <table>
<tr><td style="padding:10px 90px 10px 0px">
      <img width="200" class="img-rounded" src="https://avatars.githubusercontent.com/u/5753959?v=4" alt="Yuntian Deng">
  </td><td style="padding:10px">
    <h1>Yuntian Deng</h1>
    <b>Postdoc</b>, AI2 Mosaic<br>
    <b>Assistant Professor</b>, UWaterloo (Starts Fall '24)<br>
    <b>Associate</b>, Harvard SEAS<br>
    <b>Faculty Affiliate</b>, Vector Institute (Starts Fall '24)<br>
    PhD in CS, Harvard<br>
    <span style="font-size:16px"><a href="cv/cv.comp.pdf">[CV]</a> <a href="https://scholar.google.com/citations?user=tk0e5lYAAAAJ&hl=en&oi=ao">[Google Scholar]</a> <a href="https://twitter.com/yuntiandeng">[Twitter]</a></span> <br>

      </td>
  </tr>
  </table>
<br>
</div>


<p style="font-size: 16px">
I am a postdoc at the Mosaic team at AI2 and an incoming assistant professor at the University of Waterloo. My research interests are Natural Language Processing and Machine Learning. I also enjoy building <a href="demos/">demos</a> such as <a href="https://huggingface.co/spaces/yuntian-deng/implicit-cot-math">Grade School Math Solver w/o CoT</a>, <a href="https://huggingface.co/spaces/yuntian-deng/gpt2-multiplication">Multiplication Predictor w/o CoT</a>, <a href="https://wildchat.yuntiandeng.com">WildChat Visualizer</a>, <a href="https://openaiwatch.com/">OpenAI Watch</a>, <a href="https://steganography.live">Linguistic Steganography</a>, <a href="https://huggingface.co/spaces/yuntian-deng/AKSelectionPredictor">AKSelectionPredictor</a>, <a href="http://opennmt.net">OpenNMT</a>, <a href="https://huggingface.co/spaces/yuntian-deng/latex2im">Markup-to-Image Diffusion</a>, and <a href="https://im2markup.yuntiandeng.com/">Image-to-Markup</a>.
</p>
<br>

<h4>News</h4>
<ul style="font-size: 16px" id="news-list">
    <li>July 19, 2024: I built a <a href="https://huggingface.co/spaces/yuntian-deng/gpt2-multiplication">demo</a> using GPT-2 to directly produce the product of two numbers (up to 20 digits) without chain-of-thought (CoT). CoT is internalized using the approach in <a href="https://arxiv.org/pdf/2405.14838">From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step</a>. A 12-layer GPT-2 can solve <strong>20-digit multiplication</strong> with 99.5% accuracy!
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1814319104448467137" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>July 11, 2024: I built a <a href="https://huggingface.co/spaces/yuntian-deng/implicit-cot-math">demo</a> to solve grade school math problems (GSM8K)  without chain-of-thought (CoT) at 52% accuracy. CoT is internalized using the approach in <a href="https://arxiv.org/pdf/2405.14838">From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step</a>. Surprisingly, it even works in languages not used during internalization finetuning!
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1811448907161043224" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>June 19, 2024: I built a website, <a href="https://wildchat.yuntiandeng.com">wildchat.yuntiandeng.com</a>, for interactive search of WildChat, allowing keyword, toxicity, IP, language, and country-based searches of 1M WildChat conversations.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1803496908259991963" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>May 29, 2024: Our paper, <a href="https://arxiv.org/pdf/2405.14838">From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step</a>, is now publicly available! This paper proposes a simple yet effective method to teach language models to internalize chain-of-thought reasoning by gradually removing intermediate steps and finetuning.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1795854740879774036" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Apr 26, 2024: I built a demo, <a href="https://huggingface.co/spaces/yuntian-deng/AKSelectionPredictor">AKSelectionPredictor</a>, to predict whether a paper will be selected by <a href="https://twitter.com/_akhaliq">@_akhaliq</a> into Hugging Face papers based on its title, abstract, and authors.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1783888775950561673" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Mar 5, 2024: Our dataset, <a href="https://wildchat.allen.ai">WildChat</a>, is used in Anthropic's <a href="https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf">Claude 3</a> for evaluating refusals.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1765127045246284084" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Nov 14, 2023: Our dataset, <a href="https://wildchat.allen.ai">WildChat</a>, is now publicly available! It is a corpus of 650K real-world user-ChatGPT interactions, characterized by over 60 languages and a diversity of user prompts.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1724503257601458575" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Nov 7, 2023: Our paper, <a href="https://arxiv.org/pdf/2311.01460.pdf">Implicit Chain of Thought Reasoning via Knowledge Distillation</a>, is now publicly available! This paper trains LMs that can reason internally using hidden states instead of articulating all reasoning steps like humans.
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1721934898582229498" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Mar 29, 2023: <a href="https://openaiwatch.com/">OpenAIWatch.com</a> is launched! It tracks GPT-4's nondeterministic behavior even with greedy decoding in unicorn illustrations. ðŸ¦„ 
        <a class="twitter-link" href="https://twitter.com/yuntiandeng/status/1641108596510343168" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Mar 29, 2023: Our <a href="https://huggingface.co/spaces/yuntian-deng/ChatGPT">GPT Chatbot</a>, based on Yuvraj Sharma's <a href="https://huggingface.co/spaces/ysharma/ChatGPT4">code</a>, is now live! It provides free acess to GPT with the aim of collecting dialogue data for research purposes.
    </li>
    <li>Oct 18, 2022: Our paper, <a href="https://aclanthology.org/2022.emnlp-main.815.pdf">Model Criticism for Long-Form Text Generation</a>, is now publicly available! This paper uses model criticism in latent space to quantify various notions of high-level coherence in long-form text generation.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1582410985226108930" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Oct 12, 2022: <a href="https://huggingface.co/spaces/yuntian-deng/latex2im">Markup-to-Image Diffusion Models demo</a> is now live! This project uses a diffusion model to learn how to render various types of markups, including LaTeX.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1580255172340879360" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Jun 2, 2020: Our paper, <a href="https://papers.nips.cc/paper/2020/file/01a0683665f38d8e5e567b3b15ca98bf-Paper.pdf">Cascaded Text Generation with Markov Transformers</a>, is available! It allows parallel, fast, autoregressive, and accurate text generation using a high-order Markov model.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1267866675904417801" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Apr 26, 2020: Introducing <a href="https://openreview.net/pdf?id=B1l4SgHKDH">Residual Energy-Based Models for Text Generation</a>, a globally-normalized approach to text generation! Our approach uses a global discriminator to guide the traditional locally-normalized language model to produce text that's more indistinguishable from human-written text.
    </li>
    <li>Sep 5, 2019: <a href="https://steganography.live">Neural Linguistic Steganography demo</a> is now live! This project lets you hide secret messages in natural language using arithmetic coding.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/1169647490284605443" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Dec 19, 2016: Excited to introduce <a href="http://opennmt.net">OpenNMT</a>, an open-source neural machine translation toolkit developed for industrial and academic use.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/810900018907533313" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
    <li>Sep 19, 2016: Excited to announce that we've provided a solution to OpenAI's <a href="https://github.com/openai/requests-for-research/blob/master/_requests_for_research/im2latex.html">requests-for-research im2latex challenge</a> using neural sequence-to-sequence learning! Check out the visualizations <a href="https://im2markup.yuntiandeng.com">here</a>.
        <a class="twitter-link" href="https://twitter.com/srush_nlp/status/777901557585178624" target="_blank">
            <img src="images/twitter_logo.svg" alt="Tweet">
        </a>
    </li>
</ul>
<button id="toggle-news-btn" onclick="toggleNews()">Show More</button>

<!--h3> Current Research Area </h3>
<p style="font-size: 18px">
<ul style="font-size: 18px">
  <li> Deep generative models for probabilistic text generation. </li>
</ul>
</p-->

<br>
<h4>Representative Works</h4>
<p style="font-size: 18px">These are some of my representative works. For the full list of papers, visit <a href="/papers">here</a> or my <a href="https://scholar.google.com/citations?user=tk0e5lYAAAAJ">Google Scholar page</a>.</p>
<table>
{% for paper in site.data.papers.notable %}

  <tr><td style="padding:10px">
      {% if paper.image %}
      <a href="{{paper.pdf}}"><img width="300" style="min-width:100px" src="{{paper.image}}" alt=""></a>
      {% else %}
      <a href="{{paper.pdf}}"><img height="75" style="min-width:100px" src="https://avatar.tobi.sh/{{paper.title}}" alt=""></a>

      {% endif %}
</td><td style="padding:10px; font-size: 16px">
<a class="paper" href="{{paper.pdf}}">
{{paper.title}}
</a><br>
{{paper.authors}}.<br>
{{paper.conference}} <br>
{% if paper.notes %}
{{paper.notes}}<br>
{% else %}
{% endif %}

<br>

</td></tr>

{% endfor %}
</table>

<!--h4>Prospective Students</h4>
<p style="font-size: 16px">
I plan to hire multiple PhD/MS students at UWaterloo, home to 5 NLP professors! Strong consideration will be given to those who can tackle the below challenge by Feb 2024: Can we use LM's hidden states to reason multiple problems simultaneously? See <a href="cv/challenge.png">this picture</a> for details.
</p>

<p style="font-size: 16px">
<strong>Important Note:</strong> Due to the high volume of inquiries, I kindly request that all prospective students direct their initial communications through the submission of their response to the challenge mentioned above. Please refrain from sending reminders without addressing this challenge. This approach ensures that your application is considered with the attention it deserves and aligns with our group's focus on meaningful and engaged research discussion.
</p-->

<!--h4>Contact</h4>

<div class="paper-section">
    Science and Engineering Complex 5.443 <br>
    150 Western Avenue <br>
    Boston, MA 02134 <br>
    USA
</div-->
<br>
